# Text Summarization
[Blog c·ªßa Google v·ªÅ Model v√† Dataset](https://research.google/blog/exploring-transfer-learning-with-t5-the-text-to-text-transfer-transformer/).  
[Trang th√¥ng tin chi ti·∫øt v·ªÅ Dataset](https://huggingface.co/datasets/billsum).  
## Dataset
Dataset ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† dataset BillSum, g·ªìm c√°c d·ª± lu·∫≠t c·ªßa qu·ªëc h·ªôi M·ªπ v√† bang California (‚ÄúUS Congressional and California state bills‚Äù) v√† t√≥m t·∫Øt c·ªßa ch√∫ng.  
Bao g·ªìm c√°c ƒë·∫∑c tr∆∞ng: N·ªôi dung c·ªßa Bill, t√≥m t·∫Øt, ti√™u ƒë·ªÅ (ch·ªâ c√≥ v·ªõi d·ª± lu·∫≠t qu·ªëc h·ªôi, kh√¥ng c√≥ v·ªõi California), ƒë·ªô d√†i c·ªßa n·ªôi dung, ƒë·ªô d√†i t√≥m t·∫Øt.  

![](./report_data/BillSumImg.png)  
*·∫¢nh ch·ª•p m·ªôt ph·∫ßn d·ªØ li·ªáu g·ªëc ch∆∞a qua ti·ªÅn x·ª≠ l√Ω.*  

## Ti·ªÅn x·ª≠ l√Ω dataset  
```
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("google-t5/t5-small")
```  
D·ªØ li·ªáu ƒë∆∞·ª£c tokenized theo nh∆∞ b√°o c√°o c·ªßa m√¥ h√¨nh g·ªëc, bao g·ªìm c√°c b∆∞·ªõc:  
	M·ªôt  
	Hai  
	Ba  
	B·ªën  
	NƒÉm  
test
## Model  
Model ƒë∆∞·ª£c s·ª≠ d·ª•ng l√† *google-t5/t5-small* b·ªüi Google.  
M·ª•c ti√™u c·ªßa h·ªç khi t·∫°o ra model n√†y l√† d√πng n√≥ cho nhi·ªÅu t√°c v·ª• kh√°c nhau v·ªõi m·ªôt model duy nh·∫•t, m·ªôt metric duy nh·∫•t, m·ªôt thu·∫≠t to√°n t·ªëi ∆∞u duy nh·∫•t nh·∫±m ƒë∆°n gi·∫£n h√≥a qu√° tr√¨nh so s√°nh gi·ªØa c√°c b·ªô d·ªØ li·ªáu v√† c√°c b√†i to√°n kh√°c nhau.
N√≥ l√† m·ªôt model ·ª©ng d·ª•ng Transformer v·ªõi input/output ƒë·ªÅu l√† vƒÉn b·∫£n (Kh√°c v·ªõi model Bart, c≈©ng c·ªßa Google).  
Tuy nhi√™n v·ªÅ c√°i c·ªët l√µi c·ªßa Transformer th√¨ kh√¥ng c√≥ s·ª± thay ƒë·ªïi ƒë√°ng k·ªÉ n√™n nh√≥m t√°c gi·∫£ ƒë√£ h∆∞·ªõng ng∆∞·ªùi ƒë·ªçc t·ªõi b√°o c√°o g·ªëc c·ªßa Transformer ƒë·ªÉ hi·ªÉu r√µ h∆°n.  
  
"We use a simplified form of position embeddings
where each ‚Äúembedding‚Äù is simply a scalar that is added to the corresponding logit used
for computing the attention weights. For efficiency, we also share the position embedding
parameters across all layers in our model, though within a given layer each attention head
uses a different learned position embedding"
"To summarize, our model is roughly equivalent to the original Transformer proposed by
Vaswani et al. (2017) with the exception of removing the Layer Norm bias, placing the layer
normalization outside the residual path, and using a different position embedding scheme.
Since these architectural changes are orthogonal to the experimental factors we consider in
our empirical survey of transfer learning, we leave the ablation of their impact for future
work."
  
ƒê√¢y l√† h·ªèi chatGpt ƒë·ªÉ ƒë·ªçc, m√† th·∫•y kh√¥ng ƒë√°ng tin t√≠ n√†o c·∫£ n√™n th√¥i ch·∫Øc x√≥a ph·∫ßn n√†y r·ªìi ƒë·ªçc paper cho ch·∫Øc  
"Certainly! The architecture of the Text-to-Text Transfer Transformer (T5) model is based on the Transformer architecture, which has been highly successful in natural language processing (NLP) tasks. Here are the key components:

Encoder-Decoder Structure:
T5 follows the standard Transformer architecture, consisting of an encoder and a decoder.
The encoder processes the input text, while the decoder generates the output text.
Both encoder and decoder consist of multiple layers of self-attention and feed-forward neural networks.
Unified Text-to-Text Format:
T5 reframes all NLP tasks into a consistent format: both input and output are treated as text strings.
This allows T5 to handle a wide range of tasks without task-specific modifications.
Pre-training and Fine-tuning:
T5 is pre-trained on a large corpus of text data using unsupervised learning.
During pre-training, it learns to predict masked tokens (similar to BERT) and also learns to generate text.
Fine-tuning involves training T5 on specific downstream tasks with labeled data.
Task-Specific Heads:
T5 uses task-specific heads (output layers) for different tasks.
For example, a translation task would have a different head than a summarization task.
Shared Vocabulary:
T5 uses a shared vocabulary for both input and output tokens.
This simplifies the model and allows it to handle diverse tasks.
Task Prefixes:
T5 introduces task-specific prefixes to guide the model during fine-tuning.
For instance, a translation task might have the prefix ‚ÄúTranslate English to French: ‚Ä¶‚Äù
Overall, T5‚Äôs strength lies in its versatility‚Äîit can be fine-tuned for various NLP tasks by simply adjusting the task-specific head and providing appropriate prefixes during fine-tuning. üòäüöÄ

If you have any more questions or need further details, feel free to ask!"
  
  
### Pre-train dataset
Model ƒë√£ ƒë∆∞·ª£c pre-train tr√™n t·∫≠p dataset *Colossal Clean Crawled Corpus (C4)*, v·ªën l√† m·ªôt t·∫≠p d·ªØ li·ªáu vƒÉn b·∫£n kh·ªïng l·ªì ƒë∆∞·ª£c crawl t·ª´ d·ªØ li·ªáu kh·∫Øp n∆°i tr√™n internet.  
Nh√≥m Google th·∫•y t·∫≠p ƒë√≥ c√≥ s·ªë l∆∞·ª£ng l·ªõn nh∆∞ng ch·∫•t l∆∞·ª£ng c·ª±c th·∫•p n√™n h·ªç ƒë√£ ti·∫øn h√†nh "l·ªçc" l·∫°i b·ªô d·ªØ li·ªáu nh∆∞ sau:  
"""
‚Ä¢ Ch·ªâ gi·ªØ nh·ªØng c√¢u k·∫øt th√∫c b·∫±ng d·∫•u c√¢u. (L√†: "? . !")  
‚Ä¢ Lo·∫°i b·ªè c√°c trang web √≠t h∆°n 3 c√¢u, ch·ªâ gi·ªØ nh·ªØng c√¢u d√†i h∆°n 4 ch·ªØ.  
‚Ä¢ Lo·∫°i b·ªè c√°c trang c√≥ nh·ªØng t·ª´ "nh·∫°y c·∫£m".
‚Ä¢ Nhi·ªÅu trang ƒë∆∞a ra c·∫£nh b√°o c·∫ßn b·∫≠t Javascript n√™n h·ªç lo·∫°i b·ªè nh·ªØng c√¢u n√†o c√≥ ch·ªØ "Javascript".
‚Ä¢ Lo·∫°i b·ªè c√°c trang c√≥ c·ª•m t·ª´ "Lorem Ipsum" v√¨ n√≥ l√† vƒÉn m·∫´u ƒë·ªÉ t·∫°m.
‚Ä¢ M·ªôt s·ªë trang web s·∫Ω ph·∫£i ch·ª©a code. V√¨ ngo·∫∑c nh·ªçn "{" ƒë∆∞·ª£c d√πng trong nhi·ªÅu ng√¥n ng·ªØ l·∫≠p tr√¨nh (nh∆∞ Javascript, v·ªën ƒë∆∞·ª£c d√πng r·∫•t nhi·ªÅu tr√™n web),  lo·∫°i b·ªè trang n√†o ch·ª©a ngo·∫∑c nh·ªçn.  
‚Ä¢ Lo·∫°i b·ªè c√°c k√Ω hi·ªáu d·∫´n ngu·ªìn (Nh∆∞ c·ªßa Wikipedia l√† "[1], [C·∫ßn d·∫´n ch·ª©ng],...") n√™n lo·∫°i b·ªè h·∫øt c√°c k√Ω hi·ªáu ƒë√≥.  
‚Ä¢ Many pages had boilerplate policy notices, so we removed any lines containing the
strings ‚Äúterms of use‚Äù, ‚Äúprivacy policy‚Äù, ‚Äúcookie policy‚Äù, ‚Äúuses cookies‚Äù, ‚Äúuse of
cookies‚Äù, or ‚Äúuse cookies‚Äù.
‚Ä¢ ƒê·ªÉ gi·∫£m s·ª± tr√πng l·∫∑p cho b·ªô d·ªØ li·ªáu, ti·∫øn h√†nh lo·∫°i b·ªè c√°c b·ªô 3 c√¢u li√™n ti·∫øp b·ªã tr√πng trong c·∫£ b·ªô d·ªØ li·ªáu, gi·ªØ l·∫°i ƒë√∫ng m·ªôt b·ªô.
## Metric  
### Rouge score 
* L√† nh√≥m c√°c ƒë·ªô ƒëo ƒë∆∞·ª£c d√πng ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng c·ªßa text summarization. C√°ch m√† Rough score ho·∫°t ƒë·ªông l√† so s√°nh vƒÉn b·∫£n t√≥m t·∫Øt ƒë∆∞·ª£c t·∫°o ra v√† vƒÉn b·∫£n t√≥m t·∫Øt tham chi·∫øu.
#### a.	Rouge-N: 
-	ƒêo l∆∞·ªùng **t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa n-gram** (c·ª•m t·ª´ n t·ª´ li√™n ti·∫øp) trong t√≥m t·∫Øt m√°y so v·ªõi t√≥m t·∫Øt tham chi·∫øu.
-	Trong rouge-n, n c√≥ th·ªÉ l√† 1 ho·∫∑c 2. 
-	V√≠ d·ª•: ‚ÄúI love her very much‚Äù. Rouge-1: ( I ) , ( love ), ( her ), ( very ), ( much ).Rouge-2: ( I love ), ( love her ), ( her very ), ( very much )
-	C√°ch t√≠nh c·ª• th·ªÉ c·ªßa Rouge 1 v√† Rouge 2:
Machine result: ‚Äúthe cat is on the mat‚Äù. 
Reference result: ‚Äúthe cat sat on the red mat‚Äù.
-	**Rouge-1:** 
+ Li·ªát k√™ c√°c unigrams:
Machine result: ["the", "cat", "is", "on", "the", "mat"] => 6
Reference result: ["the", "cat", "sat", "on", "the", ‚Äúred‚Äù, "mat"] => 7
+ ƒê·∫øm s·ªë l∆∞·ª£ng unigrams ph√π h·ª£p gi·ªØ machine v·ªõi reference:
 	["the", "cat",  "on", "the", "mat"]   => 5
+ T√≠nh precision ( P ), recall ( R ) v√† f1-score ( F1 )
**P = s·ªë unigrams ph√π h·ª£p / t·ªïng s·ªë unigrams trong machine result.** P= 5/6 = 0.833.
**R = s·ªë unigrams ph√π h·ª£p / t·ªïng s·ªë unigrams trong reference result.** R = 5/7 = 0.714.
**F1 = (2xPxR) / (P+R)**. F1 = (2x0.833x0.714)/(0.833+0.714) = 0.769
-	**Rouge-2:**
+ Li·ªát k√™ c√°c unigrams:
Machine result: ["the cat", "cat is", "is on", "on the", "the mat"] => 5
Reference result: ["the cat", "cat sat","sat on","on the", "the red",‚Äúred mat‚Äù] => 6
+ ƒê·∫øm s·ªë l∆∞·ª£ng unigrams ph√π h·ª£p gi·ªØ machine v·ªõi reference:
 	["the cat", "on the"]   => 2
+ T√≠nh precision ( P ), recall ( R ) v√† f1-score ( F1 )
**P = s·ªë unigrams ph√π h·ª£p / t·ªïng s·ªë unigrams trong machine result.** P = 2/5 = 0.4
**R = s·ªë unigrams ph√π h·ª£p / t·ªïng s·ªë unigrams trong reference result.** R = 2/6 = 0.333
**F1 = (2xPxR) / (P+R).** F1 = (2x0.4x0.333)/(0.4+0.333) = 0.364
#### b. Rouge-L:
-	ƒêo l∆∞·ªùng **chi·ªÅu d√†i chu·ªói con chung d√†i nh·∫•t** (Longest Common Subsequence - LCS) gi·ªØa t√≥m t·∫Øt m√°y v√† t√≥m t·∫Øt tham chi·∫øu. Thay v√¨ ch·ªâ quan t√¢m ƒë·∫øn c√°c n-gram c·ª• th·ªÉ, ROUGE-L xem x√©t c√°c chu·ªói con d√†i nh·∫•t m√† c·∫£ hai c√¢u c√πng c√≥ v√† ƒë√°nh gi√° m·ª©c ƒë·ªô tr√πng kh·ªõp v·ªÅ tr·∫≠t t·ª± t·ª´.
-	T√≠nh 3 ch·ªâ s·ªë: Precision ( P ), Recall ( R ), F1-score ( F1 )
+ P: t·ª∑ l·ªá ƒë·ªô d√†i c·ªßa LCS v·ªõi t·ªïng s·ªë t·ª´ trong machine result. 
   P = |LCS| / length of machine result.
+ R: t·ª∑ l·ªá ƒë·ªô d√†i c·ªßa LCS v·ªõi t·ªïng s·ªë t·ª´ trong reference result.
   R = |LCS| / length of reference result.
+ F1 = (2xPxR) / (P+R)
-	V√≠ d·ª•: 
 Machine result: ‚Äúthe cute cat is on the mat‚Äù. => 7.
 Reference result: ‚Äúthe cute cat sat on the red mat‚Äù. => 8
+ T√¨m chu·ªói con gi·ªëng nhau d√†i nh·∫•t: ‚Äúthe cute cat‚Äù => len = 3.
+ T√≠nh P, R, F1:
P = 3/7 = 0.429
R = 3/8 = 0.375
F1 = (2xPxR) / (P+R) = 0.281
#### c.	Rouge-S:
-	ƒêo **d·ª±a tr√™n c√°c c·∫∑p t·ª´** (bigram) m√† kh√¥ng y√™u c·∫ßu c√°c t·ª´ trong c·∫∑p ph·∫£i li·ªÅn k·ªÅ nhau nh∆∞ng v·∫´n gi·ªØ nguy√™n th·ª© t·ª± xu·∫•t hi·ªán. ROUGE-S ƒë√°nh gi√° kh·∫£ nƒÉng c·ªßa t√≥m t·∫Øt m√°y trong vi·ªác b·∫£o t·ªìn c√°c m·ªëi quan h·ªá gi·ªØa c√°c t·ª´ trong t√≥m t·∫Øt tham chi·∫øu.
-	T√≠nh 3 ch·ªâ s·ªë: P, R, F1
+ Precision (P): T·ª∑ l·ªá skip-bigram ph√π h·ª£p so v·ªõi t·ªïng s·ªë skip-bigram trong t√≥m t·∫Øt m√°y.
+ Recall (R): T·ª∑ l·ªá skip-bigram ph√π h·ª£p so v·ªõi t·ªïng s·ªë skip-bigram trong t√≥m t·∫Øt tham chi·∫øu.
+ F1 = (2xPxR) / (P+R)
-	V√≠ d·ª•: Machine result : "the cat is on the mat" Reference result: "the cat sat on the red mat"
+ Li·ªát k√™ c√°c skip-bigrams trong machine result v√† reference result.
Skip-bigrams trong machine result: "the cat", "the is", "the on",‚Äùthe the‚Äù, "the mat", "cat is", "cat on", ‚Äúcat the‚Äù, "cat mat", "is on", ‚Äúis the‚Äù, "is mat", "on the", "on mat", ‚Äúthe mat‚Äù => 15
Skip-bigrams trong t√≥m t·∫Øt tham chi·∫øu: "the cat", "the sat", "the on", ‚Äúthe the‚Äù, "the red", "the mat", "cat sat", "cat on", ‚Äúcat the‚Äù, "cat red", "cat mat", "sat on", ‚Äúsat the‚Äù, "sat red", "sat mat", "on the", "on red", "on mat", "the red", "the mat", "red mat" => 21
+ So s√°nh c√°c skip-bigrams trong t√≥m t·∫Øt m√°y v·ªõi c√°c skip-bigrams trong t√≥m t·∫Øt tham chi·∫øu ƒë·ªÉ t√¨m c√°c c·∫∑p tr√πng kh·ªõp:
"the cat", "the on", "the the", "the mat", "cat on", "cat the", "cat mat", "on the", "on mat‚Äù.  => 9
+ T√≠nh Precision, Recall v√† F1-Score
P = 9/15 = 0.6
R = 9/21 = 0.429
F1 = (2x0.6x0.429) / (0.6+0.429) = 0.5





## K·∫øt qu·∫£ hu·∫•n luy·ªán  
Kh√° t·ªët, so s√°nh tr·ª±c ti·∫øp v·ªõi k·∫øt qu·∫£ c·ªßa model c√≥ s·∫µn th√¨ cho th·∫•y n√≥ output gi·ªëng nhau.  
Cho th·∫•y qu√° tr√¨nh hu·∫•n luy·ªán ƒë√£ th√†nh c√¥ng. 
![](./report_data/OutputDemo.png)  
*·∫¢nh ch·ª•p so s√°nh gi·ªØa output c·ªßa m√¥ h√¨nh hu·∫•n luy·ªán ƒë∆∞·ª£c (3) v√† m√¥ h√¨nh c√≥ s·∫µn (2)*  

